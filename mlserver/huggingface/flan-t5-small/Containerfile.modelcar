# Model container for FLAN-T5-Small with MLServer HuggingFace Runtime
# Downloads model from HuggingFace Hub using huggingface_hub
#
# Build: podman build -t quay.io/rh_ee_sgleszer/flan-t5-small-modelcar:0.0.11 -f Containerfile.modelcar .
# Push: podman push quay.io/rh_ee_sgleszer/flan-t5-small-modelcar:0.0.11

FROM registry.access.redhat.com/ubi9/python-311:latest AS builder

USER 0

# Install huggingface_hub
RUN pip install --no-cache-dir huggingface_hub

# Download the FLAN-T5-Small model files directly to /models
RUN python -c "from huggingface_hub import snapshot_download; snapshot_download('google/flan-t5-small', local_dir='/models')"

# Copy model-settings.json to the root models directory
COPY models/flan-t5-small/model-settings.json /models/

# Copy settings.json to enable debug mode and auto-load
COPY settings.json /models/

# Final minimal image
FROM registry.access.redhat.com/ubi9-micro:latest

# Copy model files from builder
COPY --from=builder /models /models

# Labels
LABEL name="flan-t5-small-modelcar" \
      version="0.0.11" \
      summary="FLAN-T5-Small Model for MLServer HuggingFace Runtime" \
      description="Model container with google/flan-t5-small for text-to-text generation"
